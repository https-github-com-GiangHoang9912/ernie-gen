-----------  Configuration Arguments -----------
attention_probs_dropout_prob: -1.0
batch_size: 4
beam_size: 5
checkpoints: ./checkpoints
continuous_position: True
decr_every_n_nan_or_inf: 2
decr_ratio: 0.8
dev_set: ./datasets/squad_qg//dev.tsv
do_decode: True
do_lower_case: True
do_pred: True
do_test: False
do_train: False
do_val: False
epoch: 10
ernie_config_path: ernie_gen_base/ernie_config.json
eval_mertrics: Bleu_4,METEOR,ROUGE_L
eval_script: bash ./eval/tasks/squad_qg/eval.sh
hidden_dropout_prob: 0.1
in_tokens: False
incr_every_n_steps: 100
incr_ratio: 2.0
init_checkpoint: None
init_loss_scaling: 128.0
init_pretraining_params: ernie_gen_base/params
is_distributed: False
label_smooth: 0.1
learning_rate: 5e-05
length_penalty: 1.0
lr_scheduler: linear_warmup_decay
max_dec_len: 48
max_seq_len: 512
max_src_len: 512
max_tgt_len: 96
noise_prob: 0.7
num_iteration_per_drop_scope: 1
pred_batch_size: 0
pred_set: ./datasets/squad_qg//text.tsv
random_noise: True
random_seed: 43697
role_type_size: 0
save_and_valid_by_epoch: True
save_steps: 10000
skip_steps: 10
src_do_lower_case: True
src_tokenizer: FullTokenizer
src_vocab_path: None
stream_job: None
task_type: normal
test_set: ./datasets/squad_qg//test.tsv
tgt_type_id: 3
tokenized_input: False
tokenizer: FullTokenizer
train_set: ./datasets/squad_qg//train.tsv
turn_type_size: 0
use_cuda: False
use_dynamic_loss_scaling: False
use_fast_executor: True
use_fp16: False
use_multi_gpu_test: False
validation_steps: 1000
verbose: True
vocab_path: ernie_gen_base/vocab.txt
warmup_proportion: 0.1
weight_decay: 0.01
weight_sharing: True
------------------------------------------------
Namespace(attention_probs_dropout_prob=-1.0, batch_size=4, beam_size=5, checkpoints='./checkpoints', continuous_position=True, decr_every_n_nan_or_inf=2, decr_ratio=0.8, dev_set='./datasets/squad_qg//dev.tsv', do_decode=True, do_lower_case=True, do_pred=True, do_test=False, do_train=False, do_val=False, epoch=10, ernie_config_path='ernie_gen_base/ernie_config.json', eval_mertrics='Bleu_4,METEOR,ROUGE_L', eval_script='bash ./eval/tasks/squad_qg/eval.sh', hidden_dropout_prob=0.1, in_tokens=False, incr_every_n_steps=100, incr_ratio=2.0, init_checkpoint=None, init_loss_scaling=128.0, init_pretraining_params='ernie_gen_base/params', is_distributed=False, label_smooth=0.1, learning_rate=5e-05, length_penalty=1.0, lr_scheduler='linear_warmup_decay', max_dec_len=48, max_seq_len=512, max_src_len=512, max_tgt_len=96, noise_prob=0.7, num_iteration_per_drop_scope=1, pred_batch_size=0, pred_set='./datasets/squad_qg//text.tsv', random_noise=True, random_seed=43697, role_type_size=0, save_and_valid_by_epoch=True, save_steps=10000, skip_steps=10, src_do_lower_case=True, src_tokenizer='FullTokenizer', src_vocab_path=None, stream_job=None, task_type='normal', test_set='./datasets/squad_qg//test.tsv', tgt_type_id=3, tokenized_input=False, tokenizer='FullTokenizer', train_set='./datasets/squad_qg//train.tsv', turn_type_size=0, use_cuda=False, use_dynamic_loss_scaling=False, use_fast_executor=True, use_fp16=False, use_multi_gpu_test=False, validation_steps=1000, verbose=True, vocab_path='ernie_gen_base/vocab.txt', warmup_proportion=0.1, weight_decay=0.01, weight_sharing=True)
attention_probs_dropout_prob: 0.1
hidden_act: gelu
hidden_dropout_prob: 0.1
hidden_size: 768
initializer_range: 0.02
intermediate_size: 3072
max_position_embeddings: 1024
num_attention_heads: 12
num_hidden_layers: 12
type_vocab_size: 4
vocab_size: 30522
------------------------------------------------
Load model from ernie_gen_base/params
