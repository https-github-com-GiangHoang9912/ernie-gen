#load model
vocab_path="ernie_gen_large/vocab.txt"
config_path="ernie_gen_large/ernie_config.json"
init_model="ernie_gen_large/params"

#input
max_src_len=640
max_tgt_len=192
tokenized_input="true"
continuous_position="true"
batch_size=4
in_tokens="false"
tgt_type_id=3

#decode
do_decode="true"
max_dec_len=128
beam_size=5
length_penalty=1.0
use_multi_gpu_test="true"

#train
epoch=20
weight_decay=0.01
label_smooth=0.1
hidden_dropout_prob=0.1
save_and_valid_by_epoch="true"
#lr
warmup_proportion=0.1
lr_scheduler="linear_warmup_decay"
learning_rate=4e-5
#noise
random_noise="true"
noise_prob=0.7

#dataset
data_path="./datasets/cnndm/"
train_set="train.tsv"
dev_set="dev.2k.tsv"
pred_set="test.tsv"
do_train="true"
do_val="true"
do_test="false"
do_pred="true"

#evaluate
eval_script="sh ./eval/tasks/cnndm/eval.sh"
eval_mertrics="rouge-1,rouge-2,rouge-l"
