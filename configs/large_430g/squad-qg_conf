#load model
vocab_path="ernie_gen_large_430g/vocab.txt"
config_path="ernie_gen_large_430g/ernie_config.json"
init_model="ernie_gen_large_430g/params"

#input
max_src_len=512
max_tgt_len=96
tokenized_input="true"
continuous_position="true"
batch_size=4
in_tokens="false"
tgt_type_id=3

#decode
do_decode="true"
max_dec_len=48
beam_size=5
length_penalty=1.0
use_multi_gpu_test="true"

#train
epoch=10
weight_decay=0.01
label_smooth=0.1
hidden_dropout_prob=0.2
save_and_valid_by_epoch="true"
#lr
warmup_proportion=0.25
lr_scheduler="linear_warmup_decay"
learning_rate=1.25e-5
#noise
random_noise="true"
noise_prob=0.7

#dataset
data_path="./datasets/squad_qg/"
train_set="train.tsv"
dev_set="dev.tsv"
test_set="test.tsv"
do_train="true"
do_val="true"
do_test="true"

#evaluate
eval_script="sh ./eval/tasks/squad_qg/eval.sh"
eval_mertrics="Bleu_4,METEOR,ROUGE_L"
